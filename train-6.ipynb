{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 包含四个下采样层和四个上采样层的U-Net结构\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 定义下采样层\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.down4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 定义上采样层\n",
    "        self.up4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # 定义输出层\n",
    "        self.out = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 只使用前四个通道进行下采样和上采样\n",
    "        x1 = self.down1(x[:, :4, :, :])\n",
    "        x2 = self.pool1(x1)\n",
    "        x2 = self.down2(x2)\n",
    "        x3 = self.pool2(x2)\n",
    "        x3 = self.down3(x3)\n",
    "        x4 = self.pool3(x3)\n",
    "        x4 = self.down4(x4)\n",
    "        x5 = self.pool4(x4)\n",
    "        \n",
    "        x = self.up4(x5)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        \n",
    "        # 输出sigma平方值\n",
    "        sigma2 = self.out(x)\n",
    "        \n",
    "        # 从后两个通道的目标张量中提取真实的运动场v_t\n",
    "        v_t = x[:, 4:6, :, :]\n",
    "        \n",
    "        return sigma2, v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(sigma_sq, v, v_t):\n",
    "    loss = -0.5 * torch.log(sigma_sq) - (v_t - v) ** 2 / (2 * sigma_sq)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.data_files = sorted(os.listdir(self.data_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    \"\"\"\n",
    "    `__getitem__` 方法会在每次加载一个数据时被调用，\n",
    "    它会从指定路径中读取 `.npy` 文件，并将其转换为一个 PyTorch 张量。\n",
    "    然后，使用 PyTorch 提供的 `DataLoader` 类，将数据划分为批次进行训练。\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        # Load data from file\n",
    "        data = np.load(os.path.join(self.data_path, self.data_files[index]))\n",
    "        # data = data[0:4]\n",
    "        # Convert to tensor\n",
    "        data = torch.from_numpy(data).float()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, batch_size):\n",
    "    # Create data loader\n",
    "    dataset = MyDataset(data_path)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------训练部分------------------------------\n",
    "\"\"\"\n",
    "# 加载数据\n",
    "data_path = '/home/panding/code/UR/data-chair'\n",
    "batch_size = 2\n",
    "\n",
    "data_loader = load_data(data_path, batch_size)\n",
    "\n",
    "# 初始化模型、优化器和设备\n",
    "model = UNet(in_channels=6, out_channels=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10\n",
    "\n",
    "def train(model, optimizer, data_loader, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_metric = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch in data_loader:\n",
    "            # # 将数据加载到设备上\n",
    "            # batch = batch.to(device)\n",
    "            # # 将前两个通道作为输入，后两个通道作为目标输出\n",
    "            # inputs = batch[:, :2, :, :]\n",
    "            # targets = batch[:, 2:4, :, :]\n",
    "            # # 将真实的运动场作为额外的目标输出\n",
    "            # v_t = batch[:, 4:6, :, :]\n",
    "            # # 将梯度清零\n",
    "            # optimizer.zero_grad()\n",
    "            # # 前向传递\n",
    "            # sigma2, v = model(inputs)\n",
    "            # # 计算损失和评估指标\n",
    "            # loss = custom_loss(sigma2, v, targets)\n",
    "            # metric = -loss.item()\n",
    "            # # 反向传播和优化\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "\n",
    "            # # 更新损失和评估指标\n",
    "            # epoch_loss += loss.item()\n",
    "            # epoch_metric += metric\n",
    "            # num_batches += 1\n",
    "            \n",
    "            batch = batch.to(device)\n",
    "            \n",
    "\n",
    "        # 计算平均损失和评估指标\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        avg_metric = epoch_metric / num_batches\n",
    "\n",
    "        # 打印训练进度\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss={avg_loss:.4f}, Metric={avg_metric:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
