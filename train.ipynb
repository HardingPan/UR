{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Down sampling\n",
    "        self.conv1 = double_conv(in_channels, 64)\n",
    "        self.conv2 = double_conv(64, 128)\n",
    "        self.conv3 = double_conv(128, 256)\n",
    "        self.conv4 = double_conv(256, 512)\n",
    "\n",
    "        # Up sampling\n",
    "        self.up_conv1 = up_conv(512, 256)\n",
    "        self.conv5 = double_conv(512, 256)\n",
    "        self.up_conv2 = up_conv(256, 128)\n",
    "        self.conv6 = double_conv(256, 128)\n",
    "        self.up_conv3 = up_conv(128, 64)\n",
    "        self.conv7 = double_conv(128, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Down sampling\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(F.max_pool2d(x1, 2))\n",
    "        x3 = self.conv3(F.max_pool2d(x2, 2))\n",
    "        x4 = self.conv4(F.max_pool2d(x3, 2))\n",
    "\n",
    "        # Up sampling\n",
    "        x = self.up_conv1(x4)\n",
    "        x = torch.cat([x3, x], dim=1)\n",
    "        x = self.conv5(x)\n",
    "        x = self.up_conv2(x)\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "        x = self.conv6(x)\n",
    "        x = self.up_conv3(x)\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "        x = self.conv7(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(sigma_sq, v, v_t):\n",
    "    eps = 1e-8\n",
    "    sigma_sq = sigma_sq + eps\n",
    "    loss = 0.5 * torch.log(sigma_sq) + (v_t - v) ** 2 / (2 * sigma_sq)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.data_files = sorted(os.listdir(self.data_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_files)\n",
    "\n",
    "    \"\"\"\n",
    "    `__getitem__` 方法会在每次加载一个数据时被调用，\n",
    "    它会从指定路径中读取 `.npy` 文件，并将其转换为一个 PyTorch 张量。\n",
    "    然后，使用 PyTorch 提供的 `DataLoader` 类，将数据划分为批次进行训练。\n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        # Load data from file\n",
    "        data = np.load(os.path.join(self.data_path, self.data_files[index]))\n",
    "        # data = data[0:4]\n",
    "        # Convert to tensor\n",
    "        data = torch.from_numpy(data).float()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, batch_size):\n",
    "    # Create data loader\n",
    "    dataset = MyDataset(data_path)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(inputs, device):\n",
    "    inputs = inputs.cpu().numpy()\n",
    "    N = inputs.shape[0]\n",
    "    inputs_split_list = np.split(inputs, N, axis=0)\n",
    "    inputs_split_list = [np.squeeze(i, axis=0) for i in inputs_split_list]\n",
    "    # print(inputs_split_list[0].shape)\n",
    "    for i in range(N):\n",
    "        img0 = inputs_split_list[i][0]\n",
    "        img1 = inputs_split_list[i][1]\n",
    "        u = inputs_split_list[i][2]\n",
    "        v = inputs_split_list[i][3]\n",
    "\n",
    "        x, y = np.meshgrid(np.arange(img1.shape[1]), np.arange(img1.shape[0]))\n",
    "        x = np.float32(x)\n",
    "        y = np.float32(y)\n",
    "        img0 = cv.remap(img0, x+u, y+v, interpolation = 4)\n",
    "        \n",
    "    inputs_new = np.stack(inputs_split_list, axis = 0)\n",
    "    inputs_new = torch.from_numpy(inputs_new)\n",
    "\n",
    "    return inputs_new.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_metric = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            inputs = batch[:, :4, :, :]\n",
    "            remap(inputs, device)\n",
    "            v = batch[:, 2:4, :, :]\n",
    "            v_t = batch[:, 4:6, :, :]\n",
    "            inputs = remap(inputs, device)\n",
    "            # 将梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 前向传递\n",
    "            sigma2 = model(inputs)\n",
    "            # 计算损失和评估指标\n",
    "            loss = custom_loss(sigma2, v, v_t)\n",
    "            metric = -loss.item()\n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 更新损失和评估指标\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_metric += metric\n",
    "            num_batches += 1\n",
    "\n",
    "        # 计算平均损失和评估指标\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        avg_metric = epoch_metric / num_batches\n",
    "\n",
    "        # 打印训练进度\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss={avg_loss:.4f}, Metric={avg_metric:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "------------------------------训练部分------------------------------\n",
    "\"\"\"\n",
    "# 加载数据\n",
    "data_path = '/home/panding/code/UR/data-chair'\n",
    "batch_size = 8\n",
    "\n",
    "my_data_loader = load_data(data_path, batch_size)\n",
    "\n",
    "# 初始化模型、优化器和设备\n",
    "net = UNet(in_channels=4, out_channels=1)\n",
    "Adam_optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "my_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 训练循环\n",
    "my_num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss=nan, Metric=nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[946], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model\u001b[39m=\u001b[39;49mnet, optimizer\u001b[39m=\u001b[39;49mAdam_optimizer, data_loader\u001b[39m=\u001b[39;49mmy_data_loader, num_epochs\u001b[39m=\u001b[39;49mmy_num_epochs, device\u001b[39m=\u001b[39;49mmy_device)\n",
      "Cell \u001b[0;32mIn[944], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m inputs \u001b[39m=\u001b[39m batch[:, :\u001b[39m4\u001b[39m, :, :]\n\u001b[0;32m---> 13\u001b[0m remap(inputs, device)\n\u001b[1;32m     14\u001b[0m v \u001b[39m=\u001b[39m batch[:, \u001b[39m2\u001b[39m:\u001b[39m4\u001b[39m, :, :]\n\u001b[1;32m     15\u001b[0m v_t \u001b[39m=\u001b[39m batch[:, \u001b[39m4\u001b[39m:\u001b[39m6\u001b[39m, :, :]\n",
      "Cell \u001b[0;32mIn[943], line 18\u001b[0m, in \u001b[0;36mremap\u001b[0;34m(inputs, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(y)\n\u001b[1;32m     16\u001b[0m     img0 \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mremap(img0, x\u001b[39m+\u001b[39mu, y\u001b[39m+\u001b[39mv, interpolation \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m inputs_new \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mstack(inputs_split_list, axis \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m inputs_new \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(inputs_new)\n\u001b[1;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m inputs_new\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ur/lib/python3.11/site-packages/numpy/core/shape_base.py:471\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    469\u001b[0m sl \u001b[39m=\u001b[39m (\u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m),) \u001b[39m*\u001b[39m axis \u001b[39m+\u001b[39m (_nx\u001b[39m.\u001b[39mnewaxis,)\n\u001b[1;32m    470\u001b[0m expanded_arrays \u001b[39m=\u001b[39m [arr[sl] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 471\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(expanded_arrays, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m    472\u001b[0m                        dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model=net, optimizer=Adam_optimizer, data_loader=my_data_loader, num_epochs=my_num_epochs, device=my_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
